{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexUmnov/genai_course/blob/main/week1_llm_api/homework_student.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwQF4AcAXq20"
      },
      "source": [
        "# Task 1. Book summarisation\n",
        "\n",
        "3 points\n",
        "\n",
        "LLMSs are a great tool for summarization, but it is able to process only relatively short texts, as prescribed by the MAX TOKENS restrictions of the models. So, what if we want to summarize a whole book? Let's try to make a workaround for this.\n",
        "\n",
        "To test our solutions we will be using CMU dataset for book summarization. Let's start with downloading a sample of book dataset from huggingface\n",
        "\n",
        "```\n",
        "@article{kryscinski2021booksum,\n",
        "      title={BookSum: A Collection of Datasets for Long-form Narrative Summarization},\n",
        "      author={Wojciech Kry{\\'s}ci{\\'n}ski and Nazneen Rajani and Divyansh Agarwal and Caiming Xiong and Dragomir Radev},\n",
        "      year={2021},\n",
        "      eprint={2105.08209},\n",
        "      archivePrefix={arXiv},\n",
        "      primaryClass={cs.CL}\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMDjvJisXq22"
      },
      "outputs": [],
      "source": [
        "!curl -X GET \\\n",
        "     \"https://datasets-server.huggingface.co/rows?dataset=kmfoda%2Fbooksum&config=default&split=train&offset=0&limit=100\" > book_sum_dataset.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnXLVcVyXq23"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "book_dataset = json.load(open(\"book_sum_dataset.txt\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at one row of our database. Beware: a large text will get printed."
      ],
      "metadata": {
        "id": "uFU5jSBgbUM0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XbdYE1ZXq23"
      },
      "outputs": [],
      "source": [
        "book_dataset['rows'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOO5MVj7Xq24"
      },
      "outputs": [],
      "source": [
        "len(book_dataset['rows'][0]['row']['chapter'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQVxnjAaXq24"
      },
      "source": [
        "As you can see the chapters are pretty long. Let's see how many tokens we have in those chapters. Based on instruction from OpenAI we need a package `tiktoken`\n",
        "\n",
        "We'll be following this instruction:\n",
        "\n",
        "https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LMi73TXXq24"
      },
      "outputs": [],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnZO00sCXq24"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "encoder = tiktoken.encoding_for_model(\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-1X4FszXq24"
      },
      "outputs": [],
      "source": [
        "encoder.encode(\"Hello World!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please write a small function to count tokens:"
      ],
      "metadata": {
        "id": "wcb_hZAsbrnL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH2U-o6DXq25"
      },
      "outputs": [],
      "source": [
        "def count_chatgpt_tokens(text: str, tokenizer: tiktoken.Encoding) -> int:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check how many tokens are there in a very simple string:"
      ],
      "metadata": {
        "id": "GyojR5LtbvQc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCQwEhCLXq25"
      },
      "outputs": [],
      "source": [
        "count_chatgpt_tokens(\"Hello world!\", tokenizer=encoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ESlu-SQXq25"
      },
      "source": [
        "Now that we have this function, let's fing the maximum token length of a chapter?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeKeXWepXq25"
      },
      "outputs": [],
      "source": [
        "max(\n",
        "    count_chatgpt_tokens(row['row']['chapter'], encoder)\n",
        "    for row in\n",
        "    book_dataset['rows']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2fLupZBXq25"
      },
      "source": [
        "For today's LLMs this context length isn't prohibitive. However, in real-world tasks you may easily encouter text corpora or code repos having more than 128k or even 1M tokens. Moreover, with context length growing LLM's accuracy wanes. So it's useful to learn how to organize chunkwise processing of input.\n",
        "\n",
        "What we'll do is:\n",
        "1. Split the text into chunks of sentences that can fit into the context window or are just small enough for an LLM to process them accurately.\n",
        "2. Summarize each of the chunks.\n",
        "3. Concatenate all the summaries. If the total length is still above our chosen threshold, repeat the steps 1 and 2 until it's ok.\n",
        "4. Summarize the concatenations of the summaries.\n",
        "\n",
        "## Your task\n",
        "\n",
        "Write a function\n",
        "\n",
        "```summarize_long_text_with_chatgpt(chapter: str) -> str```\n",
        "\n",
        "implementing the above method of summarization.\n",
        "\n",
        "Don't forget to log the lengths each iteration to see how much the texts shrink.\n",
        "\n",
        "For a given example please analyse your intermediate and final results. Is it indeed a good summary of the text?\n",
        "\n",
        "**Hints and suggestions**:\n",
        "- Keep in mind, that MAX TOKENS restrictions takes into account both request and model answer. So, you also need to leave some tokens for a response. So we'd suggest using at least 2:1 token ratio for chapter and summary.\n",
        "- You can control the length of the summary with prompts.\n",
        "- If you just use `split(\".\")`, you won't get a proper splitting into sentences. Luckily we have convenient Python libraries for text processing. We recommend using `sent_tokenize` or `split_into_sentences` from the `nltk` library. You can also try splitting the text into chunks of paragraphs instead.\n",
        "- It's difficult to measure the quality of summarization, but please analyze at lease two examples. Are the summaries coherent?\n",
        "- If you need inspiration in prompt building, take a look at this [paper](https://arxiv.org/pdf/2312.16171v1.pdf)\n",
        "\n",
        "**Bonus parts:**\n",
        "\n",
        "- Summarized text often starts with something like \"This text is about\", and after merging the partial summaries you'll probably have things like that all over the text. You may wish to get rid of such introductory phrases either by tuning a prompt or by post editing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0Jzyc3kXq25"
      },
      "outputs": [],
      "source": [
        "!pip install -q nltk openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOVlg2hAXq26"
      },
      "outputs": [],
      "source": [
        "CHUNK_SIZE_LIMIT = 2500\n",
        "\n",
        "def summarize_long_text_with_chatgpt(chapter: str) -> str:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check yourself:**"
      ],
      "metadata": {
        "id": "Y363SX4LQ4IE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mPvXrkwXq26"
      },
      "outputs": [],
      "source": [
        "sample_chapter = book_dataset['rows'][0]['row']['chapter']\n",
        "summarized_chapter = summarize_long_text_with_chatgpt(sample_chapter)\n",
        "print(summarized_chapter[:200])\n",
        "print(len(summarized_chapter))\n",
        "assert len(summarized_chapter) < len(sample_chapter) // 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is mostly a self-check task, but we'll ask you to submit the summary to move further.\n",
        "\n",
        "**To submit**. Please submit your summary of `book_dataset['rows'][5]['row']['chapter']` created with `CHUNK_SIZE_LIMIT = 2500`. Double check that the character length of your text is at least 50 times shorter than of the original one."
      ],
      "metadata": {
        "id": "KkDqM7W0RE4c"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLa5rxx4Xq26"
      },
      "source": [
        "# Task 2. Extracting information with LLMs\n",
        "\n",
        "At the practice session we were usually happy if we got something coherent. However, in real applications we often need to obtain concrete answers. Let's explore how to do it with LLMs.."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "Sk4pLvfqR4Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "from google.colab import userdata\n",
        "openai.api_key = userdata.get('open_ai_api_key'\n",
        "\n",
        "# openai.api_key = open(\".open-ai-api-key\").read().strip()"
      ],
      "metadata": {
        "id": "cUCJ6DucR6Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's imagine that you work for a marketing agency, and you need to gather analytics about the passing events dedicated to AI and Machine Learning. For that, you need to process press releases and extract:\n",
        "- Event name,\n",
        "- Event date,\n",
        "- Number of participants,\n",
        "- Number of speakers,\n",
        "- Attendance price.\n",
        "\n",
        "Of course, you can do it manually, but it's much more fun to use Generative AI! So, your task will be to write a function that does this with only one request to OpenAI API.\n",
        "\n",
        "Below there is an example of a press release (generated by ChatGPT, of course, so that both the event and the personae are fictional). All of them are in the press_releases.zip archive in the hometask week 1 folder.\n",
        "\n",
        "<blockquote>\n",
        "<p>PRESS RELEASE\n",
        "\n",
        "InnovAI Summit 2023: A Glimpse into the Future of Artificial Intelligence</p>\n",
        "\n",
        "City of Virtue, Cyberspace - November 8, 2023 - The most anticipated event of the year, InnovAI Summit 2023, successfully concluded last weekend, on November 5, 2023. Held in the state-of-the-art VirtuTech Arena, the summit saw a massive turnout of over 3,500 participants, from brilliant AI enthusiasts and researchers to pioneers in the field.\n",
        "\n",
        "Esteemed speakers took to the stage to shed light on the latest breakthroughs, practical implementations, and ethical considerations in AI. Dr. Evelyn Quantum, renowned for her groundbreaking work on Quantum Machine Learning, emphasized the importance of this merger and how it's revolutionizing computing as we know it. Another keynote came from Prof. Leo Nexus, whose current project 'AI for Sustainability' highlights the symbiotic relationship between nature and machine, aiming to use AI in restoring our planet's ecosystems.\n",
        "\n",
        "This year's panel discussion, moderated by the talented Dr. Ada Neura, featured lively debates on the limits of AI in creative arts. Renowned digital artist, Felix Vortex, showcased how he uses generative adversarial networks to create surreal art pieces, while bestselling author, Iris Loom, explained her experiments with AI-assisted story crafting.\n",
        "\n",
        "Among other highlights were hands-on workshops, interactive Q&A sessions, and an 'AI & Ethics' debate which was particularly well-received, emphasizing the need for transparency and fairness in AI models. An exclusive 'Start-up Alley' allowed budding entrepreneurs to showcase their innovations, gaining attention from global venture capitalists and media.\n",
        "\n",
        "The event wrapped up with an announcement for InnovAI Summit 2024, set to be even grander. Participants left with a renewed enthusiasm for the vast possibilities that the AI and ML world promises.\n",
        "\n",
        "For media inquiries, please contact:\n",
        "Jane Cipher\n",
        "Director of Communications, InnovAI Summit\n",
        "Email: jane.cipher@innovai.org\n",
        "Phone: +123-4567-8910</p>\n",
        "</blockquote>\n",
        "\n",
        "More specifically, you should write a function\n",
        "\n",
        "```python\n",
        "parse_press_release(pr: str) -> dict\n",
        "```\n",
        "\n",
        "where the output should be in the format\n",
        "\n",
        "```python\n",
        "{\n",
        "  name: 'InnovAI Summit 2023',\n",
        "  date: '08.11.2023',\n",
        "  n_participants: 3500,\n",
        "  n_speakers: 4,\n",
        "  price:\n",
        "}\n",
        "```\n",
        "\n",
        "If any of the four characteristics is not mentioned in the text, put `None` in the respective field.\n",
        "\n",
        "At the end, calculate the statistics of right answers and analyse what kind of mistakes you \"model\" makes the most."
      ],
      "metadata": {
        "id": "SI_2o1xy_PeY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hints and suggestions:**\n",
        "- It's gonna be more convenient to experiment in OpenAI chat interface https://chat.openai.com/. Plus this doesn't cost API requests money.\n",
        "- You need to be very accurate with what you want from the model.\n",
        "- It will help if you specify in the prompt that the output should be in JSON format, this way you will spend less time parsing the output. But be careful. Though **gpt-4o-mini** is easily prompted to output a JSON, please check the output format. It may contain excessive formatting, for example:\n",
        "<pre><code>```json\n",
        "{\"name\": \"InnovAI Summit 2023\", ...}\n",
        "```</pre></code>\n",
        "Actually, examining LLM outputs and their format is a must when working with them\n",
        "\n",
        "- Please be careful with the details. For example, Jane Cipher in the text above is not a speaker and shouldn't be counter as such (how to get rid of a contact person?). Also pay attention to the date format,\n",
        "- If the model is too wilful with the output format, don't hesitate to show some examples. Decreasing the temperature of predictions can help reduce the creativity of the answer, which is what we want for such task.\n",
        "- Debugging an LLM-powered application may become a tough business. When you think that you've polished it, an LLM can still surprise you. So, we don't expect 100% accuracy in this task, but we expect that you do your best to achieve high quality results."
      ],
      "metadata": {
        "id": "RkEWdffj_Phj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "press_release = \"\"\"PRESS RELEASE\n",
        "\n",
        "InnovAI Summit 2023: A Glimpse into the Future of Artificial Intelligence\n",
        "\n",
        "City of Virtue, Cyberspace - November 8, 2023 - The most anticipated event of the year, InnovAI Summit 2023, successfully concluded last weekend, on November 5, 2023. Held in the state-of-the-art VirtuTech Arena, the summit saw a massive turnout of over 3,500 participants, from brilliant AI enthusiasts and researchers to pioneers in the field.\n",
        "\n",
        "Esteemed speakers took to the stage to shed light on the latest breakthroughs, practical implementations, and ethical considerations in AI. Dr. Evelyn Quantum, renowned for her groundbreaking work on Quantum Machine Learning, emphasized the importance of this merger and how it's revolutionizing computing as we know it. Another keynote came from Prof. Leo Nexus, whose current project 'AI for Sustainability' highlights the symbiotic relationship between nature and machine, aiming to use AI in restoring our planet's ecosystems.\n",
        "\n",
        "This year's panel discussion, moderated by the talented Dr. Ada Neura, featured lively debates on the limits of AI in creative arts. Renowned digital artist, Felix Vortex, showcased how he uses generative adversarial networks to create surreal art pieces, while bestselling author, Iris Loom, explained her experiments with AI-assisted story crafting.\n",
        "\n",
        "Among other highlights were hands-on workshops, interactive Q&A sessions, and an 'AI & Ethics' debate which was particularly well-received, emphasizing the need for transparency and fairness in AI models. An exclusive 'Start-up Alley' allowed budding entrepreneurs to showcase their innovations, gaining attention from global venture capitalists and media.\n",
        "\n",
        "The event wrapped up with an announcement for InnovAI Summit 2024, set to be even grander. Participants left with a renewed enthusiasm for the vast possibilities that the AI and ML world promises.\n",
        "\n",
        "For media inquiries, please contact: Jane Cipher Director of Communications, InnovAI Summit Email: jane.cipher@innovai.org Phone: +123-4567-8910\"\"\""
      ],
      "metadata": {
        "id": "kdpHnyhxB_t3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_press_release(pr: str) -> dict:\n",
        "    pass"
      ],
      "metadata": {
        "id": "9JElaQayBfvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parse_press_release(press_release)"
      ],
      "metadata": {
        "id": "DhbK6gNtDK7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Testing\n",
        "We've prepared a small dataset for you to test your prompt on.\n",
        "Provided you've written your function, try running the following code.\n",
        "At the end you also have an opportunity to look at the results in a table side-by-side in `with_results.csv`.\n",
        "Your goal is to get at least 60% of fields right.."
      ],
      "metadata": {
        "id": "QXYAYit8QRQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gdown\n",
        "!gdown -O press_release_extraction.csv https://docs.google.com/spreadsheets/d/15IGdc3MV8864lxrLxsug0Ij480p76T1EAwBM7WGT_OI/export?format=csv"
      ],
      "metadata": {
        "id": "HIn7_IT4Snml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "pr_df = pandas.read_csv(\"press_release_extraction.csv\")\n",
        "pr_df.head()"
      ],
      "metadata": {
        "id": "F-b6lWRjS77X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pr_df.pr_parsed[0]"
      ],
      "metadata": {
        "id": "W4JndnYrlz2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "parsed_list = []\n",
        "fields = {\n",
        "    \"name\": str,\n",
        "    \"date\": str,\n",
        "    \"n_speakers\": int,\n",
        "    \"n_participants\": int,\n",
        "    \"price\": str\n",
        "}\n",
        "correct_fields = 0\n",
        "for row in pr_df.itertuples():\n",
        "    parsed_release = parse_press_release(row.pr_text)\n",
        "    parsed_list.append(json.dumps(parsed_release, indent=4))\n",
        "    golden = json.loads(row.pr_parsed)\n",
        "    for field, field_type in fields.items():\n",
        "        golden_field = golden[field]\n",
        "        parsed_field = parsed_release.get(field)\n",
        "        try:\n",
        "            parsed_field = field_type(parsed_field)\n",
        "        except (ValueError, TypeError):\n",
        "            pass\n",
        "        if golden_field == parsed_field:\n",
        "            correct_fields += 1\n",
        "        else:\n",
        "            print(f\"For {golden['name']} {field} {parsed_release.get(field)} doesn't seem the same as {golden[field]}\")\n",
        "\n",
        "print(correct_fields)"
      ],
      "metadata": {
        "id": "Xu3Yi8wPTQwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pr_df['results'] = parsed_list\n",
        "pr_df.to_csv(\"with_results.csv\")"
      ],
      "metadata": {
        "id": "horwgFpUArhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To submit**. You'll need to submit the file `with_results.csv`.\n",
        "\n",
        "Before running the following code, please double check that:\n",
        "\n",
        "- Every item in the 'results' column is a valid json with fields name, date, n_speakers, n_participants, price.\n",
        "- You get at least 60% of the fields correctly."
      ],
      "metadata": {
        "id": "SzMFk4bDSn-P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2.1 Make sure to try both Anthropic and OpenAI\n",
        "\n",
        "It's important here to compare different models. We suggest you try at least one model from OpenAI and one model from Anthropic. However, if you'd like to, you can also try different tiers of models (i.e. gpt4o vs gpt4o-mini)."
      ],
      "metadata": {
        "id": "Z5o-c51v08p6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2.2 Advanced structured output\n",
        "\n",
        "As we've seen in the seminar, ChatGPT supports outputting in a specific format of a pydantic structure. Because in this case, our output has predefined fields, we can make use of it. Define the structure, set up the output format and measure the quality.\n",
        "\n",
        "Here's an example of a pydantic model for the output with a simple validator:"
      ],
      "metadata": {
        "id": "K-YSX3dl8DzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Any\n",
        "from pydantic import BaseModel, field_validator\n",
        "\n",
        "class PressRelease(BaseModel):\n",
        "    n_speakers: int\n",
        "\n",
        "    @field_validator('n_speakers')\n",
        "    @classmethod\n",
        "    def speaker_number_positive(cls, value: int) -> int:\n",
        "        if value <= 0:\n",
        "            raise ValueError('Number of speakers should be negative')\n",
        "        return value\n"
      ],
      "metadata": {
        "id": "PAh7TsaTefsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You task here is to finish the model to incorporate all the required fields.\n",
        "\n",
        "Keep in mind, that for each python type like `int` or `str`, you can make it `Optional`, which then will also allow it to be `None`. However, depending on how you prompted your model you might receive \"None\" (string) instead of `None`. In that case you can have a choice of types, like `int | str`.\n",
        "\n",
        "You also need to write a validator for at least the `date` field so that both DD.MM.YYYY and DD.MM.YYYY-DD.MM.YYYY formats were acceptable.\n",
        "\n",
        "\n",
        "Optionally try to think of some more ways you can validate the output. Some of the examples are:\n",
        "- The price is in format CUR #NUMBER, i.e. EUR 100;\n",
        "- Check that the date mentioned in the name of the event is consistent with the date in `date` field.\n",
        "\n",
        "\n",
        "Then run the inference with structured input tied to that model. Make sure to incorporate retries based on Validation Errors in case the LLM didn't fill the fields correctly.\n",
        "\n",
        "To do that you can catch `pydantic.ValidationError`"
      ],
      "metadata": {
        "id": "NTcB8a4BenKw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL0uQL48Xq26"
      },
      "source": [
        "# Task 3: Bonus task.\n",
        "\n",
        "1 point\n",
        "\n",
        "It's quite important to understand the current limitations of the technology. As for LLMs, there are still plenty of weak spots. They can struggle even with such an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9In58MpiXq26"
      },
      "outputs": [],
      "source": [
        "sentence = \"How many tokens are in this sentence?\"\n",
        "print(f\"Actual token count: {len(encoder.encode(sentence))}\")\n",
        "print(f\"ChatGPT thinks it's: {get_chatgpt_answer(sentence)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or with this one:"
      ],
      "metadata": {
        "id": "BoxMBnYwTufy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKo2RPToXq27"
      },
      "outputs": [],
      "source": [
        "# example\n",
        "sentence = \"Reverse this sentence character by character\"\n",
        "reversed_sentence = get_chatgpt_answer(sentence)\n",
        "print(reversed_sentence[::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLM doing math\n",
        "\n",
        "Math is also not too easy for LLMs which are getting better at counting and mathematical reasoning thanks to chain-of-thought generation, but can still struggle with symbolic algebra.\n",
        "\n",
        "Let us look at an example:"
      ],
      "metadata": {
        "id": "rnGfrv2A6cDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"Let's define a mathematical operation x * y := xy + x + y. Is it associative?\"\n",
        "print(get_chatgpt_answer(sentence))"
      ],
      "metadata": {
        "id": "6K-vA6f05_Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The solution by ChatGPT-4**\n",
        "\n",
        "The\n",
        "\n",
        "To determine if the operation $*$ is associative, we need to check if:\n",
        "\n",
        "$$(a * b) * c = a * (b * c)$$\n",
        "\n",
        "for all real numbers $a$, $b$, and $c$. If this equality holds for all real numbers, then the operation is associative.\n",
        "\n",
        "Given the operation $x∗y:=xy+x+y$:\n",
        "\n",
        "Calculating $(a∗b)∗c$:\n",
        "\n",
        "First,\n",
        "\n",
        "$$a∗b=ab+a+b.$$\n",
        "\n",
        "Using this result:\n",
        "\n",
        "$$(a∗b)∗c=(ab+a+b)∗c=$$\n",
        "$$=(ab+a+b)c+(ab+a+b)+c=$$\n",
        "$$=abc+ac+bc+ab+a+b+c$$\n",
        "\n",
        "Calculating $a∗(b∗c)$:\n",
        "\n",
        "First,\n",
        "\n",
        "$$b∗c=bc+b+c.$$\n",
        "\n",
        "Using this result:\n",
        "\n",
        "$$a∗(b∗c)=a∗(bc+b+c)=$$\n",
        "$$=a(bc+b+c)+a+bc+b+c=$$\n",
        "$$=abc+ab+ac+a+bc+b+c$$\n",
        "\n",
        "Comparing the two results:\n",
        "\n",
        "$$(a∗b)∗c=abc+ac+bc+ab+a+b+c$$\n",
        "\n",
        "$$a∗(b∗c)=abc+ab+ac+a+bc+b+c$$\n",
        "\n",
        "The two expressions are not equal for all real numbers $a$, $b$, and $c$. Therefore, the operation $*$ is not associative.\n",
        "\n",
        "**End**"
      ],
      "metadata": {
        "id": "vNSuynxx6tRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's analyze this solution. You can see that ChatGPT knows definitions and does well with logic, but fails at the very last stage where it can't understand that\n",
        "\n",
        "$$abc+ac+bc+ab+a+b+c$$\n",
        "\n",
        "and\n",
        "\n",
        "$$abc+ab+ac+a+bc+b+c$$\n",
        "\n",
        "is the same expression with permuted summands."
      ],
      "metadata": {
        "id": "2wEDULPl-Phj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yqVeXG9Xq27"
      },
      "source": [
        "## Task 3*\n",
        "\n",
        "Find out what is it you are good at, but ChatGPT cannot do. Please try to be objective. Bonus points for analyzing stability of the failures of ChatGPT and their dependence on prompt formulation."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pTEBjB7gOhhI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}